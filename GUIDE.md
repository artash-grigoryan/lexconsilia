# ğŸ‡®ğŸ‡¹ LexConsilia - SystÃ¨me RAG pour Documents Juridiques Italiens

## ğŸ“‹ Vue d'Ensemble

SystÃ¨me RAG (Retrieval-Augmented Generation) spÃ©cialisÃ© pour le droit italien avec:

- **Italian-Legal-BERT** (embeddings spÃ©cialisÃ©s 768 dimensions)
- **ChromaDB** (base vectorielle)
- **Ollama** (gÃ©nÃ©ration de rÃ©ponses)
- **LangChain** (chunking intelligent)
- **NestJS** (API REST)

## ğŸš€ DÃ©marrage Rapide

```bash
# 1. DÃ©marrer les services Docker
docker-compose up -d

# 2. VÃ©rifier que tout tourne
docker-compose ps

# 3. Lancer l'application
npm run start:dev

# 4. Ouvrir Swagger
open http://localhost:3000/api
```

## ğŸ“¡ Services

| Service      | Port  | Description         |
| ------------ | ----- | ------------------- |
| NestJS API   | 3000  | API REST + Swagger  |
| ChromaDB     | 8000  | Base vectorielle    |
| Italian-BERT | 8080  | Embeddings 768 dims |
| Ollama       | 11434 | GÃ©nÃ©ration rÃ©ponses |
| MongoDB      | 27017 | Base de donnÃ©es     |

## ğŸ”§ API Endpoints

### Indexation

```bash
# Indexer un texte
POST /rag/index/text
{
  "content": "Articolo 2043...",
  "type": "LAW",
  "metadata": {"title": "Codice Civile"}
}

# Indexer un PDF
POST /rag/index/pdf
multipart/form-data: file=@document.pdf

# Indexer plusieurs PDFs
POST /rag/index/pdfs
multipart/form-data: files=@doc1.pdf, files=@doc2.pdf
```

### Consultation

```bash
# Poser une question
POST /rag/query
{
  "query": "Come funziona la responsabilitÃ  civile?",
  "type": "QUESTION",
  "maxResults": 5
}

# Analyser un PDF sans indexation
POST /rag/analyze/pdf
multipart/form-data: file=@document.pdf, query=RÃ©sume ce document

# Statistiques
GET /rag/stats
```

## âš™ï¸ Configuration SystÃ¨me

### Embeddings

- **Type:** ChromaDB par dÃ©faut (384 dimensions)
- **ModÃ¨le:** sentence-transformers/all-MiniLM-L6-v2
- **Avantage:** Rapide, lÃ©ger, pas de service externe

### ModÃ¨le Ollama

- **ModÃ¨le:** `mistral:7b-instruct-q4_0`
- **Taille:** ~4 GB (quantifiÃ© Q4)
- **MÃ©moire requise:** 7-8 GB Docker RAM
- **Contexte:** 32768 tokens

### Chunking

- **MÃ©thode:** LangChain RecursiveCharacterTextSplitter
- **Taille:** 1000 caractÃ¨res
- **Overlap:** 200 caractÃ¨res
- **SÃ©parateurs:** Paragraphes â†’ Phrases â†’ Mots

### Performance

- **Batching:** 10 documents par batch
- **Pause:** 200ms entre batches
- **Indexation:** ~1-2s par document
- **Query:** ~30-120s âš ï¸ (CPU seulement, patience requise!)

## âš ï¸ Important: Temps de RÃ©ponse

**Les requÃªtes prennent du temps sur CPU (normal!):**

- PremiÃ¨re query: 30-90 secondes
- Queries suivantes: 30-60 secondes
- Sur GPU: 10-50x plus rapide

**Pourquoi c'est lent?**

- Ollama sur CPU (pas de GPU)
- ModÃ¨le quantifiÃ© Q4 (optimisÃ© mais toujours 4GB)
- RAM Docker limitÃ©e (7.7 GB)
- Context window: 4096 tokens

**Soyez patient! ğŸ• C'est normal d'attendre 1-2 minutes.**

## âš ï¸ DÃ©pannage Rapide

```bash
# Reset complet ChromaDB
docker-compose down chromadb
docker volume rm lexconsilia_chromadb_data
docker-compose up -d chromadb

# Reconstruire Italian-BERT
docker-compose build --no-cache huggingface-embeddings
docker-compose up -d --force-recreate huggingface-embeddings

# VÃ©rifier les services
curl http://localhost:8000/api/v1/heartbeat  # ChromaDB
curl http://localhost:8080/health            # Italian-BERT
curl http://localhost:11434/api/tags         # Ollama
curl http://localhost:3000/rag/stats         # API

# Voir les logs
docker logs -f lexconsilia-italian-bert
docker logs -f lexconsilia-chromadb
```

## ğŸ§ª Test Complet

```bash
# 1. Indexer un document
curl -X POST http://localhost:3000/rag/index/text \
  -H "Content-Type: application/json" \
  -d '{
    "content": "Articolo 2043 del Codice Civile: Qualunque fatto doloso o colposo, che cagiona ad altri un danno ingiusto, obbliga colui che ha commesso il fatto a risarcire il danno.",
    "type": "LAW",
    "metadata": {
      "title": "Codice Civile - Articolo 2043",
      "source": "Codice Civile Italiano"
    }
  }'

# 2. Poser une question
curl -X POST http://localhost:3000/rag/query \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Come funziona la responsabilitÃ  civile in Italia?",
    "type": "QUESTION",
    "maxResults": 3
  }'
```

## ğŸ“Š Configuration

### Variables d'environnement (.env optionnel)

```env
PORT=3000
CHROMADB_URL=http://localhost:8000
HUGGINGFACE_EMBEDDINGS_URL=http://localhost:8080
OLLAMA_URL=http://localhost:11434
```

### ParamÃ¨tres optimisÃ©s

- **Batch size:** 10 documents (CPU optimisÃ©)
- **Chunk size:** 1000 caractÃ¨res (LangChain)
- **Chunk overlap:** 200 caractÃ¨res
- **Context window:** 32768 tokens (Ollama)
- **Embeddings:** 768 dimensions (Italian-BERT)

## âœ… Logs de SuccÃ¨s

Au dÃ©marrage:

```
[ItalianEmbeddingsService] ğŸ‡®ğŸ‡¹ Italian-Legal-BERT embeddings service is available
[ChromaDBService] ChromaDB collection "legal_documents_italian" initialized successfully
[DocumentProcessorService] DocumentProcessorService initialized with LangChain text splitter
```

Lors de l'indexation:

```
[DocumentProcessorService] ğŸ“„ LangChain splitting: 5000 chars â†’ 6 chunks
[ChromaDBService] ğŸ‡®ğŸ‡¹ Generating embeddings for 6 documents...
[ChromaDBService] âœ… Generated 6 Italian legal embeddings
[ChromaDBService] Added 6 documents to ChromaDB
```

Pour gros PDF (batching):

```
[ChromaDBService] ğŸ‡®ğŸ‡¹ Generating embeddings for 53 documents in batches of 10...
[ChromaDBService] ğŸ“¦ Batch 1/6: Processing 10 documents...
[ChromaDBService] ğŸ“¦ Batch 2/6: Processing 10 documents...
...
[ChromaDBService] âœ… Generated 53 Italian legal embeddings in 6 batches
```

## ğŸ¯ Architecture Technique

```
PDF/Texte
   â†“
LangChain (chunking intelligent)
   â†“
Batching (10 chunks/batch)
   â†“
Italian-Legal-BERT (768 dims)
   â†“
ChromaDB (stockage vectoriel)
   â†“
Query â†’ Italian-BERT â†’ ChromaDB â†’ Top K docs
   â†“
Ollama (gÃ©nÃ©ration rÃ©ponse)
   â†“
RÃ©ponse + Sources
```

## ğŸ“š Documentation Swagger

Toute la documentation API interactive: **http://localhost:3000/api**

---

**Version:** 1.0  
**Date:** 7 octobre 2025  
**Status:** âœ… Production Ready
